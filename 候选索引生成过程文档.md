# SWIRL 候选索引生成过程详细文档

## 概述

本文档详细说明了SWIRL（基于强化学习的数据库索引选择系统）中候选索引的完整生成过程，包括表列的读入、过滤、在整个实验中的保存形式，以及在强化学习中如何转化成状态空间。

## 1. 表列读入过程

### 1.1 数据库连接与表结构获取

候选索引生成的第一步是从数据库中读取表结构信息：

```python
# 文件位置: swirl/schema.py
class Schema(object):
    def __init__(self, benchmark_name, scale_factor, filters={}):
        # 获取数据库连接参数
        db_host = os.getenv('DATABASE_HOST', 'localhost')
        db_port = os.getenv('DATABASE_PORT', '54321')
        
        # 创建数据库连接器
        generating_connector = PostgresDatabaseConnector(None, autocommit=True, host=db_host, port=db_port)
        
        # 创建表生成器，读取表结构
        table_generator = TableGenerator(
            benchmark_name=benchmark_name.lower(), 
            scale_factor=scale_factor, 
            database_connector=generating_connector
        )
```

### 1.2 表结构解析

表生成器通过解析CREATE TABLE语句来获取列信息：

```python
# 文件位置: index_selection_evaluation/selection/table_generator.py
def _read_column_names(self):
    # 读取CREATE TABLE语句文件
    filename = self.directory + "/" + self.create_table_statements_file
    with open(filename, "r") as file:
        data = file.read().lower()
    
    # 分割CREATE TABLE语句
    create_tables = data.split("create table ")[1:]
    
    for create_table in create_tables:
        splitted = create_table.split("(", 1)
        if len(splitted) < 2:
            continue
            
        # 创建表对象
        table = Table(splitted[0].strip())
        self.tables.append(table)
        
        # 解析列定义
        table_content = splitted[1]
        end_pos = table_content.find(");")
        if end_pos != -1:
            table_content = table_content[:end_pos]
        
        # 分割列定义并创建列对象
        columns = table_content.split(",\n")
        for column in columns:
            column = column.strip()
            if not column or column.startswith("primary key"):
                continue
            name = column.split(" ", 1)[0].strip()
            if name:
                column_object = Column(name)
                table.add_column(column_object)
                self.columns.append(column_object)
```

### 1.3 列信息收集

所有表的列信息被收集到一个统一的列表中：

```python
# 文件位置: swirl/schema.py
self.columns = []
for table in self.tables:
    for column in table.columns:
        self.columns.append(column)
```

## 2. 列过滤过程

### 2.1 过滤机制设计

SWIRL支持多种列过滤机制，通过配置文件中指定的过滤器来减少候选索引的数量：

```python
# 文件位置: swirl/schema.py
for filter_name in filters.keys():
    filter_class = getattr(importlib.import_module("swirl.schema"), filter_name)
    filter_instance = filter_class(filters[filter_name], self.database_name)
    self.columns = filter_instance.apply_filter(self.columns)
```

### 2.2 表行数过滤器

最常用的过滤器是基于表行数的过滤器，用于排除小表：

```python
# 文件位置: swirl/schema.py
class TableNumRowsFilter(object):
    def __init__(self, threshold, database_name):
        self.threshold = threshold
        self.connector = PostgresDatabaseConnector(database_name, autocommit=True, host=db_host, port=db_port)
        self.connector.create_statistics()

    def apply_filter(self, columns):
        output_columns = []
        
        for column in columns:
            table_name = column.table.name
            try:
                # 查询表的行数估计
                result = self.connector.exec_fetch(
                    f"SELECT reltuples::bigint AS estimate FROM pg_class where relname='{table_name}'"
                )
                
                if result is None or len(result) == 0:
                    logging.warning(f"Table {table_name} not found in database, skipping column filter")
                    output_columns.append(column)
                    continue
                
                table_num_rows = result[0]
                
                # 只保留行数大于阈值的表的列
                if table_num_rows > self.threshold:
                    output_columns.append(column)
            except Exception as e:
                logging.warning(f"Error checking table {table_name}: {e}, including column in filter")
                output_columns.append(column)
        
        logging.warning(f"Reduced columns from {len(columns)} to {len(output_columns)}.")
        return output_columns
```

### 2.3 配置文件中的过滤设置

在实验配置文件中指定过滤参数：

```json
{
  "column_filters": {
    "TableNumRowsFilter": 10000
  }
}
```

## 3. 候选索引生成过程

### 3.1 工作负载分析

系统首先分析工作负载，确定哪些列是可索引的：

```python
# 文件位置: swirl/workload_generator.py
def _store_indexable_columns(self, query):
    # 使用SQLGlot解析SQL语句
    try:
        parsed_sql = sqlglot.parse_one(query.sql)
        
        # 处理表别名映射
        alias_to_table = {}
        referenced_tables = set()
        
        # 收集表引用和别名
        for table_exp in parsed_sql.find_all(sqlglot.exp.Table):
            table_name = _id_name(table_exp.this)
            referenced_tables.add(table_name)
            
            if table_exp.alias:
                alias_name = _id_name(table_exp.alias)
                alias_to_table[alias_name] = table_name
        
        # 收集列引用
        seen = set()
        for col_exp in parsed_sql.find_all(sqlglot.exp.Column):
            try:
                col_name = _id_name(col_exp.this)
            except Exception:
                col_name = str(col_exp)
            
            qualifier = None
            try:
                qualifier_exp = col_exp.args.get("table")
                if qualifier_exp is not None:
                    qualifier = _id_name(qualifier_exp)
            except Exception:
                qualifier = None
            
            # 确定候选表
            candidate_tables = []
            if qualifier:
                base_table = alias_to_table.get(qualifier, qualifier)
                candidate_tables = [base_table]
            else:
                candidate_tables = list(referenced_tables)
            
            # 匹配列到可索引列
            for wc in self.workload_columns:
                if wc.name != col_name:
                    continue
                if wc.table.name in candidate_tables:
                    key = (wc.table.name, wc.name)
                    if key not in seen:
                        query.columns.append(wc)
                        seen.add(key)
    except Exception as e:
        logging.warning(f"SQL parsing failed: {e}")
```

### 3.2 列组合生成

基于过滤后的列，系统生成不同宽度的索引组合：

```python
# 文件位置: swirl/utils.py
def create_column_permutation_indexes(columns, max_index_width):
    result_column_combinations = []
    
    # 按表分组列
    table_column_dict = {}
    for column in columns:
        if column.table not in table_column_dict:
            table_column_dict[column.table] = set()
        table_column_dict[column.table].add(column)
    
    # 生成不同宽度的索引组合
    for length in range(1, max_index_width + 1):
        unique = set()
        count = 0
        for key, columns_per_table in table_column_dict.items():
            # 使用itertools.permutations生成排列
            unique |= set(itertools.permutations(columns_per_table, length))
            count += len(set(itertools.permutations(columns_per_table, length)))
        print(f"{length}-column indexes: {count}")
        
        result_column_combinations.append(list(unique))
    
    return result_column_combinations
```

### 3.3 候选索引对象创建

每个列组合被包装成Index对象：

```python
# 文件位置: index_selection_evaluation/selection/candidate_generation.py
def syntactically_relevant_indexes(query, max_index_width):
    columns = query.columns
    
    # 按表分组可索引列
    indexable_columns_per_table = {}
    for column in columns:
        if column.table not in indexable_columns_per_table:
            indexable_columns_per_table[column.table] = set()
        indexable_columns_per_table[column.table].add(column)
    
    # 生成所有可能的列组合
    possible_column_combinations = set()
    for table in indexable_columns_per_table:
        columns = indexable_columns_per_table[table]
        for index_length in range(1, max_index_width + 1):
            possible_column_combinations |= set(
                itertools.permutations(columns, index_length)
            )
    
    # 创建Index对象
    return [Index(p) for p in possible_column_combinations]
```

## 4. 实验中的保存形式

### 4.1 全局可索引列存储

在实验对象中，候选索引以分层结构保存：

```python
# 文件位置: swirl/experiment.py
class Experiment(object):
    def prepare(self):
        # 获取全局可索引列
        self.globally_indexable_columns = self.workload_generator.globally_indexable_columns
        
        # 创建列排列索引
        # [[单列索引], [2列组合], [3列组合]...]
        self.globally_indexable_columns = utils.create_column_permutation_indexes(
            self.globally_indexable_columns, self.config["max_index_width"]
        )
        
        # 扁平化存储
        self.globally_indexable_columns_flat = [
            item for sublist in self.globally_indexable_columns for item in sublist
        ]
        
        logging.info(f"Feeding {len(self.globally_indexable_columns_flat)} candidates into the environments.")
```

### 4.2 索引大小预测

系统预先计算每个候选索引的存储消耗：

```python
# 文件位置: swirl/utils.py
def predict_index_sizes(column_combinations, database_name):
    connector = PostgresDatabaseConnector(database_name, autocommit=True, host=db_host, port=db_port)
    connector.drop_indexes()
    cost_evaluation = CostEvaluation(connector)
    
    predicted_index_sizes = []
    parent_index_size_map = {}
    
    for column_combination in column_combinations:
        potential_index = Index(column_combination)
        cost_evaluation.what_if.simulate_index(potential_index, True)
        
        full_index_size = potential_index.estimated_size
        index_delta_size = full_index_size
        
        # 计算增量大小（多列索引减去父索引的大小）
        if len(column_combination) > 1:
            index_delta_size -= parent_index_size_map[column_combination[:-1]]
        
        predicted_index_sizes.append(index_delta_size)
        cost_evaluation.what_if.drop_simulated_index(potential_index)
        parent_index_size_map[column_combination] = full_index_size
    
    return predicted_index_sizes
```

## 5. 强化学习中的状态空间转换

### 5.1 动作空间定义

候选索引在强化学习中被转换为离散动作空间：

```python
# 文件位置: swirl/action_manager.py
class ActionManager(object):
    def get_action_space(self):
        return spaces.Discrete(self.number_of_actions)
    
    def get_initial_valid_actions(self, workload, budget):
        # 初始化动作状态：0表示未执行，1表示单列索引已存在
        self.current_action_status = [0 for action in range(self.number_of_columns)]
        
        # 初始化有效动作：FORBIDDEN_ACTION表示不可执行，ALLOWED_ACTION表示可执行
        self.valid_actions = [self.FORBIDDEN_ACTION for action in range(self.number_of_actions)]
        self._remaining_valid_actions = []
        
        # 基于工作负载和预算确定有效动作
        self._valid_actions_based_on_workload(workload)
        self._valid_actions_based_on_budget(budget, current_storage_consumption=0)
        
        return np.array(self.valid_actions)
```

### 5.2 多列索引动作管理

对于多列索引，系统实现了特殊的动作管理逻辑：

```python
# 文件位置: swirl/action_manager.py
class MultiColumnIndexActionManager(ActionManager):
    def __init__(self, indexable_column_combinations, action_storage_consumptions, sb_version, max_index_width, reenable_indexes):
        # 存储列组合和对应的动作索引
        self.indexable_column_combinations = indexable_column_combinations
        self.indexable_column_combinations_flat = [
            item for sublist in self.indexable_column_combinations for item in sublist
        ]
        self.number_of_actions = len(self.indexable_column_combinations_flat)
        
        # 创建列到索引的映射
        self.column_to_idx = {}
        for idx, column in enumerate(self.indexable_column_combinations[0]):
            c = column[0]
            self.column_to_idx[c] = idx
        
        # 创建列组合到索引的映射
        self.column_combination_to_idx = {}
        for idx, column_combination in enumerate(self.indexable_column_combinations_flat):
            cc = str(column_combination)
            self.column_combination_to_idx[cc] = idx
        
        # 创建候选依赖映射（用于多列索引的递进构建）
        self.candidate_dependent_map = {}
        for indexable_column_combination in self.indexable_column_combinations_flat:
            if len(indexable_column_combination) > max_index_width - 1:
                continue
            self.candidate_dependent_map[indexable_column_combination] = []
        
        for column_combination_idx, indexable_column_combination in enumerate(self.indexable_column_combinations_flat):
            if len(indexable_column_combination) < 2:
                continue
            dependent_of = indexable_column_combination[:-1]
            self.candidate_dependent_map[dependent_of].append(column_combination_idx)
```

### 5.3 状态空间表示

系统提供多种观察管理器来将环境状态转换为强化学习可用的状态表示：

#### 5.3.1 基础状态表示

```python
# 文件位置: swirl/observation_manager.py
class SingleColumnIndexObservationManager(ObservationManager):
    def __init__(self, number_of_actions, config):
        self.number_of_features = (
            self.number_of_actions  # 每个动作是否已执行
            + self.number_of_query_classes  # 每个查询类的频率
            + 1  # 当前预算
            + 1  # 当前存储消耗
            + 1  # 初始工作负载成本
            + 1  # 当前工作负载成本
        )
    
    def get_observation(self, environment_state):
        observation = np.array(environment_state["action_status"])
        observation = np.append(observation, self.frequencies)
        observation = np.append(observation, self.episode_budget)
        observation = np.append(observation, environment_state["current_storage_consumption"])
        observation = np.append(observation, self.initial_cost)
        observation = np.append(observation, environment_state["current_cost"])
        return observation
```

#### 5.3.2 嵌入式状态表示

```python
# 文件位置: swirl/observation_manager.py
class EmbeddingObservationManager(ObservationManager):
    def __init__(self, number_of_actions, config):
        self.workload_embedder = config["workload_embedder"]
        self.representation_size = self.workload_embedder.representation_size
        self.workload_size = config["workload_size"]
        
        self.number_of_features = (
            self.number_of_actions  # 动作状态
            + (self.representation_size * self.workload_size)  # 工作负载嵌入表示
            + self.workload_size  # 查询频率
            + 1  # 预算
            + 1  # 存储消耗
            + 1  # 初始成本
            + 1  # 当前成本
        )
    
    def get_observation(self, environment_state):
        # 获取工作负载嵌入
        workload_embedding = np.array(self.workload_embedder.get_embeddings(environment_state["plans_per_query"]))
        
        observation = np.array(environment_state["action_status"])
        observation = np.append(observation, workload_embedding)
        observation = np.append(observation, self.frequencies)
        observation = np.append(observation, self.episode_budget)
        observation = np.append(observation, environment_state["current_storage_consumption"])
        observation = np.append(observation, self.initial_cost)
        observation = np.append(observation, environment_state["current_cost"])
        return observation
```

#### 5.3.3 DRLinda状态表示

```python
# 文件位置: swirl/observation_manager.py
class DRLindaObservationManager(ObservationManager):
    def __init__(self, number_of_actions, config):
        self.number_of_features = (
            self.number_of_actions  # 索引配置状态
            + (self.number_of_query_classes * self.number_of_actions)  # 工作负载矩阵 k×m
            + (self.number_of_actions)  # 访问向量
        )
    
    def _update_episode_fix_data(self, state_fix_for_episode):
        # 构建工作负载矩阵和访问向量
        self._workload_matrix = [
            [0 for m in range(self.number_of_actions)] for k in range(self.number_of_query_classes)
        ]
        self._access_vector = [0 for m in range(self.number_of_actions)]
        
        for query in state_fix_for_episode["workload"].queries:
            query_id = query.nr - 1
            for column in query.columns:
                if column.global_column_id is None:
                    continue
                self._workload_matrix[query_id][column.global_column_id] = 1
                self._access_vector[column.global_column_id] += query.frequency
    
    def get_observation(self, environment_state):
        observation = np.array(environment_state["action_status"])
        observation = np.append(observation, self._workload_matrix)
        observation = np.append(observation, self._access_vector)
        return observation
```

## 6. 完整流程总结

### 6.1 数据流向图

```
数据库表结构 → 列过滤 → 工作负载分析 → 候选索引生成 → 强化学习状态空间
     ↓              ↓           ↓              ↓              ↓
  CREATE TABLE   TableNumRows   SQL解析      列组合排列     动作空间+状态空间
   语句解析       过滤器        列匹配       Index对象      观察管理器
```

### 6.2 关键数据结构

1. **列对象 (Column)**: 包含列名、表名等基本信息
2. **表对象 (Table)**: 包含表名和列列表
3. **索引对象 (Index)**: 包含列组合和估计大小
4. **动作状态**: 数组表示每个候选索引的执行状态
5. **观察向量**: 包含动作状态、工作负载信息、成本信息等

### 6.3 性能优化

1. **列过滤**: 通过TableNumRowsFilter减少候选索引数量
2. **增量大小计算**: 多列索引只计算相对于父索引的增量大小
3. **缓存机制**: 成本评估结果可以被缓存以提高性能
4. **并行处理**: 支持多环境并行训练

## 7. 配置示例

### 7.1 实验配置文件

```json
{
  "max_index_width": 3,
  "column_filters": {
    "TableNumRowsFilter": 10000
  },
  "action_manager": "MultiColumnIndexActionManager",
  "observation_manager": "SingleColumnIndexObservationManager",
  "filter_utilized_columns": false
}
```

### 7.2 关键参数说明

- `max_index_width`: 最大索引宽度，决定生成多少列的组合
- `TableNumRowsFilter`: 表行数阈值，过滤小表
- `action_manager`: 动作管理器类型
- `observation_manager`: 观察管理器类型
- `filter_utilized_columns`: 是否只保留被工作负载使用的列

## 8. 总结

SWIRL的候选索引生成过程是一个精心设计的管道，从数据库表结构读取开始，通过列过滤减少候选数量，基于工作负载分析确定可索引列，生成不同宽度的列组合，最后转换为强化学习可用的状态空间。整个过程既保证了索引选择的全面性，又通过过滤和优化机制控制了计算复杂度，为基于强化学习的索引选择提供了坚实的基础。


